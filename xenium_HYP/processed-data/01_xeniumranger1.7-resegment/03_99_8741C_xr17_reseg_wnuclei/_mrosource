#
# @include "_decoding_type_defs.mro"
#

#
# Copyright (c) 2022 10X Genomics, Inc. All rights reserved.
#

filetype json;
filetype json.zip;
filetype zarr;
filetype zarr.zip;
filetype zarr.mzip;
filetype png;
filetype png.zip;
filetype csv;
filetype html;
filetype npz;
filetype ome.tif;
filetype pkl;
filetype tar;
filetype csv.gz;
filetype parquet;
#
# @include "insitu/_insitu_counter_defs.mro"
#

filetype h5;
filetype zarr;
#
# @include "rna/_cr_ana_stages.mro"
#

#
# Copyright (c) 2021 10X Genomics, Inc. All rights reserved.
#
# Code generated by cr_ana.  DO NOT EDIT.
#

filetype bincode.lz4;
filetype h5;
filetype npy;
#
# @include "rna/_run_kmeans.mro"
#

filetype h5;
#
# @include "insitu_analyzer.mro"
#

filetype json;
filetype h5;
#
# @include "insitu_counter_core.mro"
#

filetype zarr;
filetype json;
filetype str;
filetype csv.gz;
filetype h5;
filetype zarr.zip;
filetype zarr.zip;
filetype csv;
filetype html;
filetype ome.tif;
filetype parquet;
filetype pkl;
#
# @include "_metrics_util_stage_defs.mro"
#

#
# Copyright (c) 2022 10X Genomics, Inc. All rights reserved.
#

filetype json;
filetype csv;
#
# @include "metric_calculator_cs.mro"
#

filetype csv;
filetype str;
filetype json;
filetype zarr.zip;
filetype zarr.mzip;
filetype html;
filetype zarr;
filetype h5;
filetype ome.tif;
filetype pkl;
filetype png;
filetype jpg;
filetype parquet;
#
# @include "_create_metrics_summary_csv_cs.mro"
#

# Copyright (c) 2022 10X Genomics, Inc. All rights reserved.

filetype csv;
filetype json;
#
# @include "insitu/_xenium_ranger_common.mro"
#

filetype csv;
filetype csv.gz;
filetype h5;
filetype html;
filetype json;
filetype ome.tif;
filetype parquet;
filetype zarr.zip;
filetype tiff;
filetype jpg;
filetype png;
#
# @include "_format_outputs.mro"
#

filetype html;
filetype json;
filetype ome.tif;
filetype zarr.zip;
filetype jpg;
#
# @include "_make_output_manifest.mro"
#

filetype json;
#
# @include "_segmentation_stages.mro"
#

filetype str;
#
# @include "_websummary_stages_cs.mro"
#

filetype h5;
filetype html;
filetype json;
filetype zarr.zip;
filetype zarr.mzip;
filetype png;
filetype jpg;
filetype tiff;
#
# @include "_xenium_ranger_import_segmentation.mro"
#

filetype npy;
filetype npz;
filetype json;
filetype zarr;
filetype zarr.zip;
filetype csv;
filetype ome.tif;
#
# @include "insitu/xenium_ranger_cs.mro"
#

filetype json;

#
# @include "_decoding_type_defs.mro"
#

struct SegTile(
    npz  rle_list,
    npz  row_col_idx,
    npz  vertices,
    npz  num_vertices,
    npz  z_levels,
    json tile_parameters,
)

# Structure containing parameters for SEGMENT_CELLS
struct SegmentationParams(
    # Maximum number of polygon vertices
    int   max_vertices,
    # Parameter specifying how much simplification can be performed on the
    # final polygons
    float simplify_epsilon,
    # Minimum diameter for nuclear segmentation
    float min_diameter_um,
    # Maximum diameter for expansion nuclear segmentation
    float max_diameter_um,
    # Expansion distance for expansion nuclear segmentation
    float expansion_dist_um,
    # Minimum pixel intensity
    float dapi_filter_pe,
)

struct MorphologyPyramidBuilderOutput(
    json      estimate_fov_pos_summary,
    json      make_morphology_pyramid_summary,
    ome.tif   morphology,
    ome.tif   morphology_mip,
    ome.tif   morphology_focus,
    json      pyramid_manifest,
    zarr.zip  morpho_transform_dataset,
    zarr.mzip stitching_summary,
)

struct SegOutput(
    zarr.zip cell_segmentation_dataset,
    csv.gz   cell_boundaries_csv       "Cell segmentation cell polygons CSV"        "cell_boundaries.csv.gz",
    csv.gz   nucleus_boundaries_csv    "Cell segmentation nucleus polygons CSV"     "nucleus_boundaries.csv.gz",
    parquet  cell_boundaries_pq        "Cell segmentation cell polygons parquet"    "cell_boundaries.parquet",
    parquet  nucleus_boundaries_pq     "Cell segmentation nucleus polygons parquet" "nucleus_boundaries.parquet",
    json     cell_seg_summary,
)

struct DecodingPlan(
    json     decoding_input,
    zarr.zip imaging_manifest,
    json     external_locations,
    json     mem_model_features,
)

struct StageStdOutput(
    json    metrics,
    json    report_sections,
    png.zip report_figures,
)

struct ExecutionOptions(
    int maximum_chunks,
    int blob_finder_min_batch_size,
    int image_qc_min_batch_size,
    int point_cloud_registerer_min_batch_size,
    int make_image_pyramid_min_batch_size,
    int preprocess_for_stitching_min_batch_size,
    int register_morphology_cycles_min_batch_size,
)

struct FileLink(
    string label,
    string short_label,
    file   target,
)

struct UrlLink(
    string label,
    string short_label,
    string target,
)

struct ImagingVolumeCoordinates(
    int    cycle_index,
    int    scan_index,
    string fov_name,
    string channel_name,
)

struct ImagingCycleScanFov(
    int    cycle_index,
    int    scan_index,
    string fov_name,
)

#
# @include "insitu/_insitu_counter_defs.mro"
#

# Structure holding potentially pre-computed results
struct PreComputedResults(
    zarr transcript_assignments,
)

#
# @include "rna/_cr_ana_stages.mro"
#

struct PcaOutputs(
    h5   pca_h5,
    path pca_csv,
)

#
# @include "insitu/_xenium_ranger_common.mro"
#

struct XeniumRangerPayload(
    json mem_model_features,
    json sample_sheet,
    jpg  resized_overview_image,
    json summary_cs,
    json gene_panel,
    json pyramid_manifest,
    json segmentation_plan,
    json xenium_ranger_table,
)

# Struct containing parameters for xeniumranger resegment
# this struct is a superset of SegmentationParams struct
struct ResegmentParams(
    # If true, use input nuclei instead of resegmenting nuclei
    bool  resegment_nuclei,
    # Maximum number of polygon vertices
    int   max_vertices,
    # Parameter specifying how much simplification can be performed on the
    # final polygons
    float simplify_epsilon,
    # Minimum diameter for nuclear segmentation
    float min_diameter_um,
    # Maximum diameter for expansion nuclear segmentation
    float max_diameter_um,
    # Expansion distance for expansion nuclear segmentation
    float expansion_dist_um,
    # Minimum pixel intensity.
    float dapi_filter_pe,
)

# Struct containing parameters for xeniumranger relabel
struct RelabelParams(
    # Gene panel to use for relabel
    json gene_panel,
)

# Struct containing parameters for xeniumranger import-segmentation
struct ImportSegParams(
    # Importing segmentations
    file   nuclei                "3rd party nuclear polygons",
    file   cells                 "3rd party cell polygons",
    string spatial_units         "Units of the imported polygons",
    # Importing transcripts
    csv    transcript_assignment "3rd party transcript assignments",
    json   viz_polygons          "Polygons file for visualization only",
    # Common parameters
    float  expansion_dist_um     "Expansion distance for cell segmentation",
    float  min_nucleus_area_um2  "Min nucleus area in microns squared",
    float  max_nucleus_area_um2  "Max nucleus area microns squared",
    float  min_cell_area_um2     "Min cell area in microns squared",
    float  max_cell_area_um2     "Max cell area microns squared",
    int    max_vertices          "Maximum number of polygon vertices",
    float  simplify_epsilon      "Minimum distance between polygon vertices and segments",
    csv    coordinate_transform  "File containing matrix transform from physical into pixel space.",
)

struct XrRunData(
    string run_id,
    string run_timestamp,
    string software_version,
    string command_line,
    string original_software_version,
)

# CS aux outputs organized into a struct
struct AuxOutputs(
    json      morphology_fov_locations,
    png       overview_scan,
    json      overview_scan_fov_locations,
    map<tiff> per_cycle_channel_images,
)

struct OutputBundle(
    csv        metrics_summary,
    zarr.zip   transcripts,
    csv.gz     transcript_info_csv          "Transcript info CSV"                        "transcripts.csv.gz",
    parquet    transcript_info_pq           "Transcript info parquet"                    "transcripts.parquet",
    csv.gz     cell_info_csv                "Cell info CSV"                              "cells.csv.gz",
    parquet    cell_info_pq                 "Cell info parquet"                          "cells.parquet",
    zarr.zip   cell_segmentation            "Cell segmentation result"                   "cells.zarr.zip",
    csv.gz     nucleus_boundaries_csv       "Cell segmentation nucleus polygons CSV"     "nucleus_boundaries.csv.gz",
    csv.gz     cell_boundaries_csv          "Cell segmentation cell polygons CSV"        "cell_boundaries.csv.gz",
    parquet    nucleus_boundaries_pq        "Cell segmentation nucleus polygons parquet" "nucleus_boundaries.parquet",
    parquet    cell_boundaries_pq           "Cell segmentation cell polygons parquet"    "cell_boundaries.parquet",
    zarr.zip   analysis_zarr_zip            "Clustering result in zarr.zip format"       "analysis.zarr.zip",
    zarr.zip   cell_feature_matrix_zarr_zip "Cell-feature matrix in zarr.zip format"     "cell_feature_matrix.zarr.zip",
    h5         cell_feature_matrix_h5       "Cell-feature matrix in h5 format"           "cell_feature_matrix.h5",
    ome.tif    morphology,
    ome.tif    morphology_mip,
    ome.tif    morphology_focus,
    json       experiment_xenium            "Metadata for Xenium Explorer"               "experiment.xenium",
    html       web_summary                  "Customer-facing web summary"                "analysis_summary.html",
    path       cell_feature_matrix_mtx      "Cell-feature matrix in MEX format"          "cell_feature_matrix",
    path       analysis_csv                 "Clustering result in csv format"            "analysis",
    AuxOutputs aux_outputs                  "Auxiliary output files",
    json       gene_panel                   "Gene panel JSON",
)

# minimal subset of OutputBundle needed for Xenium Ranger to function.
struct XrMinBundle(
    csv        metrics_summary,
    zarr.zip   transcripts,
    zarr.zip   cell_segmentation "Cell segmentation result"     "cells.zarr.zip",
    ome.tif    morphology,
    ome.tif    morphology_mip,
    ome.tif    morphology_focus,
    json       experiment_xenium "Metadata for Xenium Explorer" "experiment.xenium",
    html       web_summary       "Customer-facing web summary"  "analysis_summary.html",
    AuxOutputs aux_outputs       "Auxiliary output files",
    json       gene_panel        "Gene panel JSON",
)

#
# @include "rna/_cr_ana_stages.mro"
#

stage RUN_DIFFERENTIAL_EXPRESSION_NG(
    in  h5          matrix_h5,
    in  h5          clustering_h5,
    in  bool        is_antibody_only,
    out h5          diffexp_h5,
    out path        diffexp_csv,
    src comp        "cr_ana martian diff_exp_stage",
) split (
    in  map[]       cluster_keys,
    out bincode.lz4 diffexp,
) using (
    volatile = strict,
)

stage RUN_GRAPH_CLUSTERING_NG(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    num_neighbors,
    in  float  neighbor_a,
    in  float  neighbor_b,
    in  int    input_pcs,
    in  float  resolution,
    in  int    random_seed,
    in  bool   is_antibody_only,
    in  int    threads,
    in  bool   parallel_clustering,
    out h5     clusters_h5,
    out path   clusters_csv,
    src comp   "cr_ana martian graph_clustering_stage",
) split (
    in  string feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_HIERARCHICAL_CLUSTERING(
    in  h5     matrix_h5,
    in  h5     graph_clusters_h5,
    in  bool   is_antibody_only,
    out h5     clusters_h5,
    out path   clusters_csv,
    src comp   "cr_ana martian hierarchical_clustering_stage",
) split (
    in  string feature_type,
) using (
    mem_gb  = 4,
    threads = 1,
)

stage RUN_PCA_NG(
    in  h5              matrix_h5,
    in  int             num_pca_genes,
    in  int             num_principal_comps,
    in  bool            is_spatial,
    in  map<PcaOutputs> pca_map,
    out h5              pca_h5,
    out path            pca_csv,
    src comp            "cr_ana martian pca_stage",
) split (
    in  string          feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_PCA2(
    in  h5  matrix_h5,
    in  int num_pcs,
    out npy dimred_matrix,
    src comp "cr_ana martian pca2_stage",
) split (
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_TSNE_NG(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  float  perplexity,
    in  int    input_pcs,
    in  int    max_dims,
    in  int    max_iter,
    in  int    stop_lying_iter,
    in  int    mom_switch_iter,
    in  float  theta,
    in  bool   is_antibody_only,
    out h5     tsne_h5,
    out path   tsne_csv,
    src comp   "cr_ana martian tsne_stage",
) split (
    in  int    tsne_dims,
    in  string feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

stage RUN_UMAP(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  int    n_neighbors,
    in  int    input_pcs,
    in  int    max_dims,
    in  float  min_dist,
    in  string metric,
    in  bool   is_antibody_only,
    in  string implementation,
    out h5     umap_h5,
    out path   umap_csv,
    src comp   "cr_ana martian umap_stage",
) split (
    in  int    umap_dims,
    in  string feature_type,
) using (
    mem_gb   = 1,
    threads  = 1,
    volatile = strict,
)

#
# @include "rna/_run_kmeans.mro"
#

stage RUN_KMEANS(
    in  h5     matrix_h5,
    in  h5     pca_h5,
    in  int    random_seed,
    in  int    max_clusters,
    in  int    num_bcs,
    in  int    num_pcs,
    out h5     kmeans_h5,
    out path   kmeans_csv,
    src py     "stages/analyzer/run_kmeans",
) split (
    in  int    n_clusters,
    in  string library,
) using (
    volatile = strict,
)

#
# @include "insitu_analyzer.mro"
#

pipeline INSITU_ANALYZER(
    in  h5   matrix_h5,
    in  bool disable_tsne,
    in  int  graphclust_threads,
    out h5   analysis_h5         "Clustering result in h5 format"  "analysis.h5",
    out path analysis_csv        "Clustering result in csv format"  "analysis",
    out bool skipped,
)
{
    call SETUP_ANALYZER(
        filtered_matrices_h5 = self.matrix_h5,
        disable_tsne         = self.disable_tsne,
    )

    call RUN_PCA_NG as RUN_PCA(
        matrix_h5           = SETUP_ANALYZER.preprocessed_matrix_h5,
        num_pca_genes       = null,
        num_principal_comps = null,
        pca_map             = null,
        is_spatial          = false,
    ) using (
        disabled = SETUP_ANALYZER.skip,
        volatile = true,
    )

    call RUN_KMEANS(
        matrix_h5    = SETUP_ANALYZER.preprocessed_matrix_h5,
        pca_h5       = RUN_PCA.pca_h5,
        random_seed  = null,
        max_clusters = null,
        num_bcs      = null,
        num_pcs      = null,
    ) using (
        disabled = SETUP_ANALYZER.skip,
        volatile = true,
    )

    call RUN_GRAPH_CLUSTERING_NG as RUN_GRAPH_CLUSTERING(
        matrix_h5           = SETUP_ANALYZER.preprocessed_matrix_h5,
        pca_h5              = RUN_PCA.pca_h5,
        num_neighbors       = null,
        neighbor_a          = null,
        neighbor_b          = null,
        input_pcs           = null,
        resolution          = null,
        random_seed         = null,
        is_antibody_only    = false,
        threads             = self.graphclust_threads,
        parallel_clustering = true,
    ) using (
        disabled = SETUP_ANALYZER.skip,
        volatile = true,
    )

    call COMBINE_CLUSTERING(
        kmeans_h5      = RUN_KMEANS.kmeans_h5,
        kmeans_csv     = RUN_KMEANS.kmeans_csv,
        graphclust_h5  = RUN_GRAPH_CLUSTERING.clusters_h5,
        graphclust_csv = RUN_GRAPH_CLUSTERING.clusters_csv,
    ) using (
        disabled = SETUP_ANALYZER.skip,
        volatile = true,
    )

    call RUN_DIFFERENTIAL_EXPRESSION_NG as RUN_DIFFERENTIAL_EXPRESSION(
        matrix_h5        = SETUP_ANALYZER.preprocessed_matrix_h5,
        clustering_h5    = COMBINE_CLUSTERING.clustering_h5,
        is_antibody_only = false,
    ) using (
        disabled = SETUP_ANALYZER.skip,
        volatile = true,
    )

    call RUN_TSNE_NG as RUN_TSNE(
        matrix_h5        = SETUP_ANALYZER.preprocessed_matrix_h5,
        pca_h5           = RUN_PCA.pca_h5,
        random_seed      = null,
        perplexity       = null,
        input_pcs        = null,
        max_dims         = null,
        max_iter         = null,
        stop_lying_iter  = null,
        mom_switch_iter  = null,
        theta            = null,
        is_antibody_only = false,
    ) using (
        disabled = SETUP_ANALYZER.skip_tsne,
        volatile = true,
    )

    call RUN_UMAP(
        matrix_h5        = SETUP_ANALYZER.preprocessed_matrix_h5,
        pca_h5           = RUN_PCA.pca_h5,
        random_seed      = null,
        n_neighbors      = null,
        input_pcs        = null,
        max_dims         = null,
        min_dist         = null,
        metric           = null,
        is_antibody_only = false,
        implementation   = "parallel",
    ) using (
        disabled = SETUP_ANALYZER.skip,
        volatile = true,
    )

    call SUMMARIZE_ANALYSIS(
        matrix_h5      = SETUP_ANALYZER.preprocessed_matrix_h5,
        pca_h5         = RUN_PCA.pca_h5,
        clustering_h5  = COMBINE_CLUSTERING.clustering_h5,
        diffexp_h5     = RUN_DIFFERENTIAL_EXPRESSION.diffexp_h5,
        tsne_h5        = RUN_TSNE.tsne_h5,
        umap_h5        = RUN_UMAP.umap_h5,
        pca_csv        = RUN_PCA.pca_csv,
        clustering_csv = COMBINE_CLUSTERING.clustering_csv,
        diffexp_csv    = RUN_DIFFERENTIAL_EXPRESSION.diffexp_csv,
        tsne_csv       = RUN_TSNE.tsne_csv,
        umap_csv       = RUN_UMAP.umap_csv,
    ) using (
        disabled = SETUP_ANALYZER.skip,
    )

    return (
        analysis_h5  = SUMMARIZE_ANALYSIS.analysis_h5,
        analysis_csv = SUMMARIZE_ANALYSIS.analysis_csv,
        skipped      = SETUP_ANALYZER.skip,
    )
}

stage COMBINE_CLUSTERING(
    in  h5   kmeans_h5,
    in  path kmeans_csv,
    in  h5   graphclust_h5,
    in  path graphclust_csv,
    out h5   clustering_h5,
    out path clustering_csv,
    src py   "./stages/analyzer/combine_clustering",
) using (
    mem_gb   = 2,
    vmem_gb  = 16384,
    volatile = strict,
)

stage SUMMARIZE_ANALYSIS(
    in  h5   matrix_h5,
    in  h5   pca_h5,
    in  h5   clustering_h5,
    in  h5   diffexp_h5,
    in  h5   tsne_h5,
    in  h5   umap_h5,
    in  path pca_csv,
    in  path clustering_csv,
    in  path diffexp_csv,
    in  path tsne_csv,
    in  path umap_csv,
    out h5   analysis_h5     "Clustering result in h5 format"  "analysis.h5",
    out path analysis_csv    "Clustering result in csv format"  "analysis",
    src py   "stages/analyzer/summarize_analysis",
) split (
) using (
    vmem_gb  = 16384,
    volatile = strict,
)

stage SETUP_ANALYZER(
    in  h5   filtered_matrices_h5,
    in  bool disable_tsne,
    out h5   preprocessed_matrix_h5,
    out bool skip,
    out bool skip_tsne,
    src py   "./stages/analyzer/setup_analyzer",
) using (
    mem_gb   = 8,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "insitu_counter_core.mro"
#

# In-situ counter pipeline
pipeline INSITU_COUNTER_CORE(
    in  json               mem_model_features,
    in  zarr.zip           transcripts,
    in  zarr.zip           cell_segmentation_dataset,
    in  json               gene_panel,
    in  h5                 cell_protein_matrix_h5,
    in  bool               disable_tsne,
    in  int                graphclust_threads,
    in  bool               disable_create_gene_matrix,
    in  float              count_min_q,
    # Pre-computed results
    in  PreComputedResults pre_computed,
    #
    out csv.gz             transcript_info_csv           "Transcript info CSV"      "transcripts.csv.gz",
    out parquet            transcript_info_pq            "Transcript info parquet"  "transcripts.parquet",
    out csv.gz             cell_info_csv                 "Cell info CSV"            "cells.csv.gz",
    out parquet            cell_info_pq                  "Cell info parquet"        "cells.parquet",
    out path               cell_feature_matrix_mtx       "Cell-feature matrix in MEX format"  "cell_feature_matrix",
    out zarr.zip           cell_feature_matrix_zarr_zip  "Cell-feature matrix in zarr.zip format"  "cell_feature_matrix.zarr.zip",
    out h5                 cell_feature_matrix_h5        "Cell-feature matrix in h5 format"  "cell_feature_matrix.h5",
    out h5                 analysis_h5                   "Clustering result in h5 format"  "analysis.h5",
    out path               analysis_csv                  "Clustering result in csv format"  "analysis",
    out json               gene_summary,
    out zarr.zip           nucleus_distance,
    out bool               disable_create_gene_matrix,
    out bool               disable_analyzer,
)
{
    call COMPUTE_NUCLEAR_DISTANCE(
        mem_model_features = self.mem_model_features,
        transcripts        = self.transcripts,
        cells              = self.cell_segmentation_dataset,
        max_distance       = 50,
        method             = "simplified_poly",
    ) using (
        disabled = self.disable_create_gene_matrix,
    )

    call CREATE_GENE_MATRIX(
        mem_model_features = self.mem_model_features,
        transcripts        = self.transcripts,
        cells              = self.cell_segmentation_dataset,
        gene_panel         = self.gene_panel,
        min_q              = self.count_min_q,
        # Optional pre-computed results
        assignments        = self.pre_computed.transcript_assignments,
    ) using (
        disabled = self.disable_create_gene_matrix,
    )

    call CREATE_TRANSCRIPTS_CSV(
        mem_model_features     = self.mem_model_features,
        transcript_assignments = CREATE_GENE_MATRIX.transcript_assignments,
        cell_feature_matrix_h5 = CREATE_GENE_MATRIX.cell_feature_matrix_h5,
        transcripts            = self.transcripts,
        cells                  = self.cell_segmentation_dataset,
        nucleus_distance       = COMPUTE_NUCLEAR_DISTANCE.nucleus_distance,
    ) using (
        disabled = self.disable_create_gene_matrix,
    )

    call CONCATENATE_MATRIX(
        cell_gene_matrix_h5    = CREATE_GENE_MATRIX.cell_feature_matrix_h5,
        cell_protein_matrix_h5 = self.cell_protein_matrix_h5,
    )

    call CREATE_MATRIX_MTX(
        mem_model_features     = self.mem_model_features,
        cell_feature_matrix_h5 = CONCATENATE_MATRIX.cell_feature_matrix_h5,
    ) using (
        disabled = CONCATENATE_MATRIX.disable_analyzer,
    )

    call CREATE_MATRIX_ZARR(
        mem_model_features     = self.mem_model_features,
        cell_feature_matrix_h5 = CONCATENATE_MATRIX.cell_feature_matrix_h5,
    ) using (
        disabled = CONCATENATE_MATRIX.disable_analyzer,
    )

    call INSITU_ANALYZER(
        matrix_h5          = CONCATENATE_MATRIX.cell_feature_matrix_h5,
        disable_tsne       = self.disable_tsne,
        graphclust_threads = self.graphclust_threads,
    ) using (
        disabled = CONCATENATE_MATRIX.disable_analyzer,
    )

    call SELECT_ANALYZER_OUTS(
        analysis_h5  = INSITU_ANALYZER.analysis_h5,
        analysis_csv = INSITU_ANALYZER.analysis_csv,
        skipped      = INSITU_ANALYZER.skipped,
        disabled     = CONCATENATE_MATRIX.disable_analyzer,
    )

    return (
        cell_feature_matrix_mtx      = CREATE_MATRIX_MTX.cell_feature_matrix_mtx,
        cell_feature_matrix_h5       = CONCATENATE_MATRIX.cell_feature_matrix_h5,
        cell_feature_matrix_zarr_zip = CREATE_MATRIX_ZARR.cell_feature_matrix_zarr_zip,
        analysis_h5                  = SELECT_ANALYZER_OUTS.analysis_h5,
        analysis_csv                 = SELECT_ANALYZER_OUTS.analysis_csv,
        transcript_info_csv          = CREATE_TRANSCRIPTS_CSV.transcript_info_csv,
        transcript_info_pq           = CREATE_TRANSCRIPTS_CSV.transcript_info_pq,
        cell_info_csv                = CREATE_TRANSCRIPTS_CSV.cell_info_csv,
        cell_info_pq                 = CREATE_TRANSCRIPTS_CSV.cell_info_pq,
        gene_summary                 = CREATE_GENE_MATRIX.summary,
        nucleus_distance             = COMPUTE_NUCLEAR_DISTANCE.nucleus_distance,
        disable_create_gene_matrix   = self.disable_create_gene_matrix,
        disable_analyzer             = CONCATENATE_MATRIX.disable_analyzer,
    )
}

stage CONCATENATE_MATRIX(
    in  h5   cell_gene_matrix_h5,
    in  h5   cell_protein_matrix_h5,
    out h5   cell_feature_matrix_h5  "Cell-feature matrix in h5 format"  "cell_feature_matrix.h5",
    out bool disable_analyzer,
    src py   "./stages/concatenate_matrix",
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage COMPUTE_NUCLEAR_DISTANCE(
    in  json     mem_model_features,
    in  zarr.zip transcripts,
    in  zarr.zip cells,
    in  float    max_distance,
    in  str      method,
    out zarr.zip nucleus_distance,
    src py       "./stages/compute_nuclear_distance",
) split (
    in  int      mask_index,
    in  int      tile_x,
    in  int      tile_y,
    in  int      tile_dx,
    in  int      tile_dy,
    in  float    pixel_size,
    out zarr.zip distance_transform,
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage CREATE_GENE_MATRIX(
    in  json     mem_model_features,
    in  zarr.zip transcripts,
    in  zarr.zip cells,
    in  json     gene_panel,
    in  float    min_q,
    in  zarr     assignments             "optional pre-computed assignments",
    out h5       cell_feature_matrix_h5,
    out json     summary,
    out zarr     transcript_assignments,
    src py       "./stages/create_gene_matrix",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
) retain (
    summary,
)

stage CREATE_MATRIX_MTX(
    in  json mem_model_features,
    in  h5   cell_feature_matrix_h5,
    out path cell_feature_matrix_mtx  "Cell-feature matrix in MEX format"  "cell_feature_matrix",
    src py   "./stages/create_matrix_mtx",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage CREATE_MATRIX_ZARR(
    in  json     mem_model_features,
    in  h5       cell_feature_matrix_h5,
    out zarr.zip cell_feature_matrix_zarr_zip  "Cell-feature matrix in zarr.zip format"  "cell_feature_matrix.zarr.zip",
    src py       "./stages/create_matrix_zarr",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage CREATE_TRANSCRIPTS_CSV(
    in  json     mem_model_features,
    in  zarr     transcript_assignments,
    in  h5       cell_feature_matrix_h5,
    in  zarr.zip transcripts,
    in  zarr.zip cells,
    in  zarr.zip nucleus_distance,
    out csv.gz   transcript_info_csv     "Transcript info CSV"      "transcripts.csv.gz",
    out parquet  transcript_info_pq      "Transcript info parquet"  "transcripts.parquet",
    out csv.gz   cell_info_csv           "Cell info CSV"            "cells.csv.gz",
    out parquet  cell_info_pq            "Cell info parquet"        "cells.parquet",
    src py       "./stages/create_transcripts_csv",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage SELECT_ANALYZER_OUTS(
    in  h5   analysis_h5,
    in  path analysis_csv,
    in  bool skipped,
    in  bool disabled,
    out h5   analysis_h5   "Clustering result in h5 format"  "analysis.h5",
    out path analysis_csv  "Clustering result in csv format"  "analysis",
    src py   "./stages/select_analyzer_outs",
) using (
    vmem_gb = 16384,
)

#
# @include "_metrics_util_stage_defs.mro"
#

stage SIMPLE_MERGE_METRICS(
    in  json[] summaries,
    out json   summary,
    src py     "./stages/metrics/simple_merge_metrics",
) using (
    mem_gb   = 8,
    volatile = strict,
)

stage SIMPLE_METRICS_TO_CSV(
    in  json summary,
    out csv  metrics,
    src py   "./stages/metrics/simple_metrics_to_csv",
) using (
    mem_gb   = 8,
    volatile = strict,
)

#
# @include "metric_calculator_cs.mro"
#

pipeline METRIC_CALCULATOR_CS(
    in  json     mem_model_features,
    in  zarr.zip cells,
    in  zarr.zip transcripts,
    in  h5       matrix,
    in  ome.tif  morphology_image,
    in  json     gene_panel,
    in  json     sample_sheet,
    in  bool     is_add_on_panel,
    in  string   calibration_uuid,
    in  json     input_metrics,
    in  jpg      resized_overview_image,
    in  string   xr_run_id,
    in  path     analysis_csv,
    in  parquet  transcript_info_pq,
    out json     summary,
    out json     details,
)
{
    call GENERATE_DECODING_METRICS_CS(
        mem_model_features = self.mem_model_features,
        matrix             = self.matrix,
        cells              = self.cells,
        transcripts        = self.transcripts,
        input_metrics      = self.input_metrics,
        is_add_on_panel    = self.is_add_on_panel,
    )

    call GENERATE_CELL_METRICS(
        mem_model_features = self.mem_model_features,
        matrix             = self.matrix,
        cells              = self.cells,
        transcripts        = self.transcripts,
        is_add_on_panel    = self.is_add_on_panel,
        transcript_info_pq = self.transcript_info_pq,
        analysis_csv       = self.analysis_csv,
    )

    # TODO need to move the core of this into a method called by GENERATE_WEB_SUMMARY_CS
    # also, need to move the "hidden" calibration zarr path stuff into the `summary_cs.json`
    call GENERATE_SAMPLE_METRICS(
        mem_model_features     = self.mem_model_features,
        transcripts            = self.transcripts,
        gene_panel             = self.gene_panel,
        sample_sheet           = self.sample_sheet,
        summary                = GENERATE_DECODING_METRICS_CS.summary,
        calibration_uuid       = self.calibration_uuid,
        resized_overview_image = self.resized_overview_image,
        xr_run_id              = self.xr_run_id,
    )

    call GENERATE_MORPHOLOGY_PLOTS(
        mem_model_features = self.mem_model_features,
        morphology_image   = self.morphology_image,
    )

    call SIMPLE_MERGE_METRICS as MERGE_METRICS(
        summaries = [
            GENERATE_CELL_METRICS.summary,
            GENERATE_DECODING_METRICS_CS.summary,
            GENERATE_MORPHOLOGY_PLOTS.summary,
            GENERATE_SAMPLE_METRICS.summary,
        ],
    )

    call SIMPLE_MERGE_METRICS as MERGE_DETAILS(
        summaries = [
            GENERATE_CELL_METRICS.details,
            GENERATE_MORPHOLOGY_PLOTS.details,
            GENERATE_SAMPLE_METRICS.details,
            GENERATE_DECODING_METRICS_CS.details,
        ],
    )

    return (
        summary = MERGE_METRICS.summary,
        details = MERGE_DETAILS.summary,
    )
}

stage GENERATE_DECODING_METRICS_CS(
    in  json     mem_model_features,
    in  h5       matrix,
    in  zarr.zip cells,
    in  zarr.zip transcripts,
    in  json     input_metrics,
    in  bool     is_add_on_panel,
    out json     summary,
    out json     fov_summary,
    out json     details,
    out html     report,
    src py       "./stages/metrics/generate_decoding_metrics_cs",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage GENERATE_SAMPLE_METRICS(
    in  json     mem_model_features,
    in  zarr.zip transcripts,
    in  json     gene_panel,
    in  json     sample_sheet,
    in  json     summary,
    in  jpg      resized_overview_image,
    in  string   calibration_uuid,
    in  string   xr_run_id,
    out json     summary,
    out json     details,
    src py       "./stages/metrics/generate_sample_metrics",
) split (
) using (
    mem_gb   = 8,
    volatile = strict,
)

stage GENERATE_MORPHOLOGY_PLOTS(
    in  json    mem_model_features,
    in  ome.tif morphology_image,
    out json    summary,
    out json    details,
    src py      "./stages/metrics/generate_morphology_plots",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

stage GENERATE_CELL_METRICS(
    in  json     mem_model_features,
    in  h5       matrix,
    in  zarr.zip cells,
    in  zarr.zip transcripts,
    in  bool     is_add_on_panel,
    in  parquet  transcript_info_pq,
    in  path     analysis_csv,
    out json     summary,
    out json     details,
    out html     report,
    src py       "./stages/metrics/generate_cell_metrics",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_create_metrics_summary_csv_cs.mro"
#

stage CREATE_METRICS_SUMMARY_CSV_CS(
    in  json final_summary_json,
    out csv  metrics_summary,
    src py   "stages/create_metrics_summary_csv_cs",
) using (
    mem_gb   = 2,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "insitu/_xenium_ranger_common.mro"
#

stage XR_RELABEL_TRANSCRIPTS(
    in  json     mem_model_features,
    in  zarr.zip transcripts,
    in  json     original_gene_panel,
    in  json     gene_panel,
    out zarr.zip transcripts,
    src py       "stages/xr_relabel_transcripts",
) split (
) using (
    mem_gb   = 1,
    vmem_gb  = 16384,
    volatile = strict,
)

stage XR_SELECT_DATASET(
    in  zarr.zip      original,
    in  map<zarr.zip> choices,
    out zarr.zip      dataset,
    src py            "stages/xr_select_dataset",
) using (
    mem_gb   = 1,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_format_outputs.mro"
#

stage FORMAT_OUTPUTS_CS(
    in  json      mem_model_features,
    in  html      web_summary,
    in  json      final_summary_json,
    in  json      gene_panel,
    in  json      sample_sheet,
    in  ome.tif   morphology,
    in  ome.tif   morphology_focus,
    in  ome.tif   morphology_mip,
    in  path      analysis_csv,
    in  zarr.zip  cell_feature_matrix_zarr_zip,
    in  zarr.zip  cell_segmentation,
    in  zarr.zip  transcripts,
    in  string    calibration_uuid,
    in  XrRunData xr_run_data,
    out zarr.zip  analysis_zarr_zip             "Clustering result in zarr.zip format"  "analysis.zarr.zip",
    out json      experiment_xenium             "Metadata for Xenium Explorer"  "experiment.xenium",
    src py        "stages/format_outputs_cs",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_make_output_manifest.mro"
#

stage MAKE_OUTPUT_MANIFEST(
    in  file[]     output_bundle_files,
    in  path[]     output_bundle_paths,
    in  file[]     telemetry_bundle_files,
    in  path[]     telemetry_bundle_paths,
    in  AuxOutputs aux_outputs,
    out json       output_manifest,
    src py         "stages/make_output_manifest",
) using (
    mem_gb   = 2,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_segmentation_stages.mro"
#

# segmentation stages, minus a few preflight stages
# stages in this file should not depend on the decoder_input

stage STITCH_SEGMENTATION(
    in  json        mem_model_features,
    in  ome.tif     morphology,
    in  json        pyramid_manifest,
    in  SegTile[][] seg_parts_list,
    out zarr.zip    nuclei_segmentation_dataset,
    out json        summary,
    src py          "stages/stitch_segmentation",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

stage SEGMENT_CELLS(
    in  json               mem_model_features,
    in  int                seg_partition_cycle_ix,
    in  json               segmentation_plan,
    in  SegmentationParams segmentation_params,
    in  ome.tif            morphology,
    in  json               pyramid_manifest,
    out SegTile[]          seg_parts_list,
    src py                 "stages/segment_cells",
) split (
    in  int                cycle_id,
    in  str                nuclei_channel_name,
    in  int                tile_id_x,
    in  int                tile_id_y,
    in  int                tile_width,
    in  int                tile_height,
    in  int                tile_overlap,
    in  float              zstep_um,
    in  float              scale,
    in  float              min_nuclear_area_px,
    in  float              max_nuclear_area_px,
    in  path               model_path,
    in  int                max_vertices,
    in  float              simplify_epsilon,
    in  int                cache_block_size,
    in  int                cache_number_blocks,
    in  float              dapi_filter_pe,
    out npz                rle_list,
    out npz                row_col_idx,
    out npz                vertices,
    out npz                num_vertices,
    out npz                z_levels,
    out npz                areas,
    out npz                centroids,
    out json               tile_parameters,
) using (
    mem_gb   = 8,
    vmem_gb  = 16384,
    volatile = strict,
)

stage EXPAND_NUCLEI(
    in  json     mem_model_features,
    in  ome.tif  morphology,
    in  json     pyramid_manifest,
    in  zarr.zip nuclei_dataset,
    in  int      max_vertices,
    in  float    simplify_epsilon,
    in  float    expansion_dist_um,
    in  bool     is_xr_import_segmentation,
    out zarr.zip cell_segmentation_dataset  "Cell segmentation result"  "cells.zarr.zip",
    out csv.gz   cell_boundaries_csv        "Cell segmentation cell polygons CSV"  "cell_boundaries.csv.gz",
    out csv.gz   nucleus_boundaries_csv     "Cell segmentation nucleus polygons CSV"  "nucleus_boundaries.csv.gz",
    out parquet  cell_boundaries_pq         "Cell segmentation cell polygons parquet"  "cell_boundaries.parquet",
    out parquet  nucleus_boundaries_pq      "Cell segmentation nucleus polygons parquet"  "nucleus_boundaries.parquet",
    src py       "stages/expand_nuclei",
) split (
    in  int      tile_x,
    in  int      tile_y,
    in  int      tile_dx,
    in  int      tile_dy,
    in  int      tile_overlap,
    in  int      exclude_top,
    in  int      exclude_bot,
    in  int      exclude_left,
    in  int      exclude_right,
    in  int      expansion_dist_px,
    out npz      rle_list,
    out npz      row_col_idx,
    out npz      vertices,
    out npz      num_vertices,
    out npz      labels,
    out npz      areas,
    out npz      centroids,
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

stage WRITE_CELL_NUCLEI_BOUNDARIES_FILES(
    in  json     mem_model_features,
    in  zarr.zip cells,
    out csv.gz   cell_boundaries_csv     "Cell segmentation cell polygons CSV"  "cell_boundaries.csv.gz",
    out csv.gz   nucleus_boundaries_csv  "Cell segmentation nucleus polygons CSV"  "nucleus_boundaries.csv.gz",
    out parquet  cell_boundaries_pq      "Cell segmentation cell polygons parquet"  "cell_boundaries.parquet",
    out parquet  nucleus_boundaries_pq   "Cell segmentation nucleus polygons parquet"  "nucleus_boundaries.parquet",
    src py       "stages/write_cell_nuclei_boundaries_files",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_websummary_stages_cs.mro"
#

stage CREATE_WEB_SUMMARY_CS(
    in  json                mem_model_features,
    in  string              sample_id,
    in  string              sample_desc,
    in  json[]              plot_details,
    in  path                spatial_plots,
    in  json                final_summary_json,
    in  zarr.zip            transcripts,
    in  zarr.zip            cell_segmentation_dataset,
    in  h5                  analysis_h5,
    in  h5                  matrix,
    in  bool                is_add_on_panel,
    in  map<tiff>           per_cycle_channel_images,
    in  XeniumRangerPayload payload_files,
    in  XrRunData           xr_run_data,
    in  json                xr_table,
    out html                web_summary                "Customer-facing web summary"  "analysis_summary.html",
    out json                data,
    src py                  "stages/create_web_summary_cs",
) split (
) using (
    mem_gb   = 16,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_insitu_counter_cs.mro"
#

# Given CS transcripts and cells, perform the counting and metric calculation steps
# Produces a valid CS websummary and output bundle
pipeline INSITU_COUNTER_CS(
    in  zarr.zip           transcripts,
    in  zarr.zip           cells,
    in  json               gene_panel,
    in  ome.tif            morphology,
    in  ome.tif            morphology_mip,
    in  ome.tif            morphology_focus,
    in  str                calibration_uuid,
    in  json               mem_model_features,
    in  json               sample_sheet,
    in  json               morphology_fov_json,
    in  png                overview_scan,
    in  json               overview_scan_fov_json,
    in  map<tiff>          per_cycle_channel_images,
    in  json               dx_plot_details,
    in  jpg                resized_overview_image,
    in  json               input_metrics_summary,
    in  json               pyramid_manifest,
    in  json               segmentation_plan,
    in  json[]             telemetry_bundle_files,
    in  path[]             telemetry_bundle_paths,
    in  PreComputedResults pre_computed,
    in  XrRunData          xr_run_data,
    in  json               xr_table,
    in  path               spatial_plots,
    out OutputBundle       output_bundle,
    out json               output_manifest,
    out h5                 analysis_h5,
    out json               summary_cs,
    out json               plot_details,
)
{
    call SETUP_COUNTER_CS(
        mem_model_features = self.mem_model_features,
        gene_panel         = self.gene_panel,
        sample_sheet       = self.sample_sheet,
    )

    call WRITE_CELL_NUCLEI_BOUNDARIES_FILES(
        mem_model_features = self.mem_model_features,
        cells              = self.cells,
    )

    call INSITU_COUNTER_CORE(
        mem_model_features         = self.mem_model_features,
        transcripts                = self.transcripts,
        cell_segmentation_dataset  = self.cells,
        gene_panel                 = self.gene_panel,
        cell_protein_matrix_h5     = null,
        disable_tsne               = true,
        graphclust_threads         = 8,
        disable_create_gene_matrix = false,
        count_min_q                = 20,
        pre_computed               = self.pre_computed,
    )

    call METRIC_CALCULATOR_CS(
        mem_model_features     = self.mem_model_features,
        transcripts            = self.transcripts,
        cells                  = self.cells,
        matrix                 = INSITU_COUNTER_CORE.cell_feature_matrix_h5,
        gene_panel             = self.gene_panel,
        sample_sheet           = self.sample_sheet,
        morphology_image       = self.morphology_mip,
        input_metrics          = self.input_metrics_summary,
        is_add_on_panel        = SETUP_COUNTER_CS.is_add_on_panel,
        calibration_uuid       = self.calibration_uuid,
        resized_overview_image = self.resized_overview_image,
        xr_run_id              = self.xr_run_data.run_id,
        analysis_csv           = INSITU_COUNTER_CORE.analysis_csv,
        transcript_info_pq     = INSITU_COUNTER_CORE.transcript_info_pq,
    )

    call SIMPLE_MERGE_METRICS as MERGE_METRICS(
        summaries = [
            METRIC_CALCULATOR_CS.summary,
            INSITU_COUNTER_CORE.gene_summary,
        ],
    )

    call UPDATE_COUNT_METRICS(
        original_summary    = self.input_metrics_summary,
        new_metrics_summary = MERGE_METRICS.summary,
    )

    call CREATE_WEB_SUMMARY_CS(
        mem_model_features        = self.mem_model_features,
        sample_id                 = SETUP_COUNTER_CS.sample_id,
        sample_desc               = SETUP_COUNTER_CS.sample_desc,
        plot_details              = [
            METRIC_CALCULATOR_CS.details,
            self.dx_plot_details,
        ],
        final_summary_json        = UPDATE_COUNT_METRICS.updated_summary,
        transcripts               = self.transcripts,
        cell_segmentation_dataset = self.cells,
        analysis_h5               = INSITU_COUNTER_CORE.analysis_h5,
        matrix                    = INSITU_COUNTER_CORE.cell_feature_matrix_h5,
        is_add_on_panel           = SETUP_COUNTER_CS.is_add_on_panel,
        per_cycle_channel_images  = self.per_cycle_channel_images,
        payload_files             = {
            gene_panel:             self.gene_panel,
            mem_model_features:     self.mem_model_features,
            pyramid_manifest:       self.pyramid_manifest,
            resized_overview_image: self.resized_overview_image,
            sample_sheet:           self.sample_sheet,
            segmentation_plan:      self.segmentation_plan,
            summary_cs:             UPDATE_COUNT_METRICS.updated_summary,
            # xenium_ranger_table is calculated and overwritten at websummary creation time.
            xenium_ranger_table:    null,
        },
        xr_run_data               = self.xr_run_data,
        xr_table                  = self.xr_table,
        spatial_plots             = self.spatial_plots,
    )

    call CREATE_METRICS_SUMMARY_CSV_CS(
        final_summary_json = UPDATE_COUNT_METRICS.updated_summary,
    )

    call FORMAT_OUTPUTS_CS(
        mem_model_features           = self.mem_model_features,
        sample_sheet                 = self.sample_sheet,
        analysis_csv                 = INSITU_COUNTER_CORE.analysis_csv,
        final_summary_json           = UPDATE_COUNT_METRICS.updated_summary,
        gene_panel                   = self.gene_panel,
        morphology                   = self.morphology,
        morphology_mip               = self.morphology_mip,
        morphology_focus             = self.morphology_focus,
        cell_segmentation            = self.cells,
        cell_feature_matrix_zarr_zip = INSITU_COUNTER_CORE.cell_feature_matrix_zarr_zip,
        transcripts                  = self.transcripts,
        web_summary                  = CREATE_WEB_SUMMARY_CS.web_summary,
        calibration_uuid             = self.calibration_uuid,
        xr_run_data                  = self.xr_run_data,
    )

    call MAKE_OUTPUT_MANIFEST(
        # we leave out gene_panel from output_bundle_files because currently it
        # seems it is being copied into the bundle directly from PA_SETUP in the
        # case of instrument runs
        # TODO(Peter) consider removing that and putting it here
        output_bundle_files    = [
            CREATE_METRICS_SUMMARY_CSV_CS.metrics_summary,
            self.transcripts,
            INSITU_COUNTER_CORE.transcript_info_csv,
            INSITU_COUNTER_CORE.transcript_info_pq,
            INSITU_COUNTER_CORE.cell_info_csv,
            INSITU_COUNTER_CORE.cell_info_pq,
            self.cells,
            WRITE_CELL_NUCLEI_BOUNDARIES_FILES.nucleus_boundaries_csv,
            WRITE_CELL_NUCLEI_BOUNDARIES_FILES.cell_boundaries_csv,
            WRITE_CELL_NUCLEI_BOUNDARIES_FILES.nucleus_boundaries_pq,
            WRITE_CELL_NUCLEI_BOUNDARIES_FILES.cell_boundaries_pq,
            FORMAT_OUTPUTS_CS.analysis_zarr_zip,
            INSITU_COUNTER_CORE.cell_feature_matrix_zarr_zip,
            INSITU_COUNTER_CORE.cell_feature_matrix_h5,
            self.morphology,
            self.morphology_mip,
            self.morphology_focus,
            FORMAT_OUTPUTS_CS.experiment_xenium,
            CREATE_WEB_SUMMARY_CS.web_summary,
        ],
        output_bundle_paths    = [
            INSITU_COUNTER_CORE.cell_feature_matrix_mtx,
            INSITU_COUNTER_CORE.analysis_csv,
        ],
        aux_outputs            = {
            morphology_fov_locations:    self.morphology_fov_json,
            overview_scan:               self.overview_scan,
            overview_scan_fov_locations: self.overview_scan_fov_json,
            per_cycle_channel_images:    self.per_cycle_channel_images,
        },
        telemetry_bundle_files = self.telemetry_bundle_files,
        telemetry_bundle_paths = self.telemetry_bundle_paths,
    )

    return (
        output_bundle   = {
            analysis_csv:                 INSITU_COUNTER_CORE.analysis_csv,
            analysis_zarr_zip:            FORMAT_OUTPUTS_CS.analysis_zarr_zip,
            aux_outputs: {
                morphology_fov_locations:    self.morphology_fov_json,
                overview_scan:               self.overview_scan,
                overview_scan_fov_locations: self.overview_scan_fov_json,
                per_cycle_channel_images:    self.per_cycle_channel_images,
            },
            cell_boundaries_csv:          WRITE_CELL_NUCLEI_BOUNDARIES_FILES.cell_boundaries_csv,
            cell_boundaries_pq:           WRITE_CELL_NUCLEI_BOUNDARIES_FILES.cell_boundaries_pq,
            cell_feature_matrix_h5:       INSITU_COUNTER_CORE.cell_feature_matrix_h5,
            cell_feature_matrix_mtx:      INSITU_COUNTER_CORE.cell_feature_matrix_mtx,
            cell_feature_matrix_zarr_zip: INSITU_COUNTER_CORE.cell_feature_matrix_zarr_zip,
            cell_info_csv:                INSITU_COUNTER_CORE.cell_info_csv,
            cell_info_pq:                 INSITU_COUNTER_CORE.cell_info_pq,
            cell_segmentation:            self.cells,
            experiment_xenium:            FORMAT_OUTPUTS_CS.experiment_xenium,
            gene_panel:                   self.gene_panel,
            metrics_summary:              CREATE_METRICS_SUMMARY_CSV_CS.metrics_summary,
            morphology:                   self.morphology,
            morphology_focus:             self.morphology_focus,
            morphology_mip:               self.morphology_mip,
            nucleus_boundaries_csv:       WRITE_CELL_NUCLEI_BOUNDARIES_FILES.nucleus_boundaries_csv,
            nucleus_boundaries_pq:        WRITE_CELL_NUCLEI_BOUNDARIES_FILES.nucleus_boundaries_pq,
            transcript_info_csv:          INSITU_COUNTER_CORE.transcript_info_csv,
            transcript_info_pq:           INSITU_COUNTER_CORE.transcript_info_pq,
            transcripts:                  self.transcripts,
            web_summary:                  CREATE_WEB_SUMMARY_CS.web_summary,
        },
        output_manifest = MAKE_OUTPUT_MANIFEST.output_manifest,
        analysis_h5     = INSITU_COUNTER_CORE.analysis_h5,
        summary_cs      = UPDATE_COUNT_METRICS.updated_summary,
        plot_details    = METRIC_CALCULATOR_CS.details,
    )
}

stage SETUP_COUNTER_CS(
    in  json   mem_model_features,
    in  json   gene_panel,
    in  json   sample_sheet,
    out bool   is_add_on_panel,
    out string sample_id,
    out string sample_desc,
    src py     "./stages/setup_counter_cs",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

stage UPDATE_COUNT_METRICS(
    in  json original_summary,
    in  json new_metrics_summary,
    out json updated_summary,
    src py   "stages/update_rerun_metrics",
) using (
    mem_gb   = 8,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_xenium_ranger_import_segmentation.mro"
#

# Stage to import a third party
pipeline XR_IMPORT_SEGMENTATION(
    in  json     mem_model_features,
    in  zarr.zip cell_segmentation_dataset  "Original cell segmentation dataset",
    in  ome.tif  morphology,
    in  json     pyramid_manifest,
    in  json     imported_nuclei            "3rd party nuclear polygons",
    in  json     imported_cells             "3rd party cell polygons",
    in  string   spatial_units              "Units of the imported polygons",
    in  float    expansion_dist_um          "Expansion distance for cell segmentation",
    in  float    min_nucleus_area_um2       "Min nucleus area in microns squared",
    in  float    max_nucleus_area_um2       "Max nucleus area in microns squared",
    in  float    min_cell_area_um2          "Min cell area in microns squared",
    in  float    max_cell_area_um2          "Max cell area in microns squared",
    in  int      max_vertices               "Max number of polygon vertices",
    in  float    simplify_epsilon           "Min distance between polygon vertices and segments",
    in  csv      coordinate_transform       "File containing matrix transform from physical into pixel space.",
    #
    out zarr.zip cells                      "New cell segmentation dataset",
    out json     metrics                    "Metrics relating to polygon and/or mask construction",
)
{
    call XR_IMPORT_SEGMENTATION_DATASET as IMPORT_NUCLEAR_SEGMENTATION_DATASET(
        mem_model_features        = self.mem_model_features,
        cell_segmentation_dataset = self.cell_segmentation_dataset,
        imported_segmentation     = self.imported_nuclei,
        spatial_units             = self.spatial_units,
        max_vertices              = self.max_vertices,
        simplify_epsilon          = self.simplify_epsilon,
        coordinate_transform      = self.coordinate_transform,
        is_cell                   = false,
    )

    # Pick the nuclei dataset from import if one was provided, otherwise use
    # the original.
    call XR_SELECT_DATASET as SELECT_NUCLEAR_SEGMENTATION_DATASET(
        original = self.cell_segmentation_dataset,
        choices  = {
            "imported": IMPORT_NUCLEAR_SEGMENTATION_DATASET.dataset,
        },
    )

    call XR_IMPORT_SEGMENTATION_DATASET as IMPORT_CELL_SEGMENTATION_DATASET(
        mem_model_features        = self.mem_model_features,
        cell_segmentation_dataset = self.cell_segmentation_dataset,
        imported_segmentation     = self.imported_cells,
        spatial_units             = self.spatial_units,
        max_vertices              = self.max_vertices,
        simplify_epsilon          = self.simplify_epsilon,
        coordinate_transform      = self.coordinate_transform,
        is_cell                   = true,
    )

    # If we were given nuclear segmentation, but no cell segmentation, then we
    # expand the nuclear segmentation to generate the cell
    call EXPAND_NUCLEI(
        mem_model_features        = self.mem_model_features,
        morphology                = self.morphology,
        pyramid_manifest          = self.pyramid_manifest,
        nuclei_dataset            = SELECT_NUCLEAR_SEGMENTATION_DATASET.dataset,
        max_vertices              = self.max_vertices,
        simplify_epsilon          = self.simplify_epsilon,
        expansion_dist_um         = self.expansion_dist_um,
        is_xr_import_segmentation = true,
    ) using (
        disabled = IMPORT_CELL_SEGMENTATION_DATASET.imported,
    )

    # Pick the cell seg dataset from import if one was provided, otherwise use
    # the segmentation from expansion. If we didn't expand, pick the original.
    call XR_SELECT_DATASET as SELECT_CELL_SEGMENTATION_DATASET(
        original = self.cell_segmentation_dataset,
        choices  = {
            "expanded": EXPAND_NUCLEI.cell_segmentation_dataset,
            "imported": IMPORT_CELL_SEGMENTATION_DATASET.dataset,
        },
    )

    # Merge the nuclear and cellular segmentations into a single, consistant
    # cell segmentation dataset.
    call XR_MERGE_SEGMENTATIONS(
        mem_model_features   = self.mem_model_features,
        cell_segmentation    = SELECT_CELL_SEGMENTATION_DATASET.dataset,
        nuclei_segmentation  = SELECT_NUCLEAR_SEGMENTATION_DATASET.dataset,
        spatial_units        = self.spatial_units,
        max_vertices         = self.max_vertices,
        simplify_epsilon     = self.simplify_epsilon,
        min_nucleus_area_um2 = self.min_nucleus_area_um2,
        max_nucleus_area_um2 = self.max_nucleus_area_um2,
        min_cell_area_um2    = self.min_cell_area_um2,
        max_cell_area_um2    = self.max_cell_area_um2,
    )

    call SIMPLE_MERGE_METRICS(
        summaries = [
            XR_MERGE_SEGMENTATIONS.metrics,
            IMPORT_CELL_SEGMENTATION_DATASET.metrics,
            IMPORT_NUCLEAR_SEGMENTATION_DATASET.metrics,
        ],
    )

    return (
        cells   = XR_MERGE_SEGMENTATIONS.cells,
        metrics = SIMPLE_MERGE_METRICS.summary,
    )
}

# Stage to import 3rd party segmentations from a mask (npy or tif) or as GeoJSON polygons
stage XR_IMPORT_SEGMENTATION_DATASET(
    in  json     mem_model_features,
    in  zarr.zip cell_segmentation_dataset  "Original cell segmentation dataset",
    #
    in  file     imported_segmentation      "3rd party segmentation polygons",
    in  string   spatial_units              "Units of the imported polygons",
    in  int      max_vertices               "Max number of polygon vertices",
    in  float    simplify_epsilon           "Min distance between polygon vertices and segments",
    in  csv      coordinate_transform       "File containing matrix transform from physical into pixel space.",
    in  bool     is_cell                    "True if the polygons correspond to cells",
    out zarr.zip dataset                    "New cell segmentation dataset with only cells",
    out bool     imported                   "True if the import performed",
    out json     metrics                    "Metrics relating to polygon and/or mask construction",
    src py       "stages/xr_import_segmentation_dataset",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

# Stage to merge cell and nuclei segmentations.
stage XR_MERGE_SEGMENTATIONS(
    in  json     mem_model_features,
    in  zarr.zip cell_segmentation,
    in  zarr.zip nuclei_segmentation,
    in  string   spatial_units,
    in  int      max_vertices,
    in  float    simplify_epsilon,
    in  float    min_cell_area_um2,
    in  float    max_cell_area_um2,
    in  float    min_nucleus_area_um2,
    in  float    max_nucleus_area_um2,
    #
    out zarr.zip cells                   "Merged segmentation dataset.",
    out json     metrics                 "Metrics relating to polygon and/or mask construction",
    src py       "stages/xr_merge_segmentations",
) split (
    in  map<int> tile_bounds,
    in  int      overlap_px,
    in  int[]    full_mask_shape,
    out npz      res_nuclei,
    out npz      res_cells,
    out npz      cell_polygons,
    out npz      cell_num_vertices,
    out npz      cell_polygon_labels,
    out npz      nucleus_polygons,
    out npz      nucleus_num_vertices,
    out npz      nucleus_polygon_labels,
    out npz      cell_summary,
    out json     partial_metrics,
    out bool     nuclei_tile_is_binary,
    out bool     cells_tile_is_binary,
) using (
    mem_gb   = 8,
    vmem_gb  = 16384,
    volatile = strict,
)

# Stage to import 3rd party transcript assignments and cell segmentation
# polygons for visualization
stage XR_IMPORT_TRANSCRIPT_ASSIGNMENTS(
    in  json     mem_model_features,
    in  zarr.zip cell_segmentation_dataset  "Original cell segmentation dataset",
    in  zarr.zip transcripts                "Original RNA dataset",
    in  csv      transcript_assignment      "3rd party transcript assignments",
    in  json     polygons                   "3rd party segmentation polygons",
    in  string   spatial_units              "Units of the imported polygons",
    in  float    min_area_um2               "Min allowed area in microns squared",
    in  float    max_area_um2               "Max allowed area in microns squared",
    in  int      max_vertices               "Max number of polygon vertices",
    in  float    simplify_epsilon           "Min distance between polygon vertices and segments",
    in  csv      coordinate_transform       "File containing matrix transform from physical into pixel space.",
    #
    out zarr.zip cells                      "New cell segmentation dataset with only cells",
    out zarr     transcript_assignments     "The transcript assignments",
    out json     metrics,
    src py       "stages/xr_import_transcripts",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "insitu/xenium_ranger_cs.mro"
#

pipeline XENIUM_RANGER_CS(
    in  path            output_bundle,
    in  RelabelParams   relabel_params,
    in  ResegmentParams resegment_params,
    in  ImportSegParams import_seg_params,
    in  string          run_id,
    in  string          run_timestamp,
    in  string          command_line,
    in  string          software_version,
    out csv             metrics_summary,
    out zarr.zip        transcripts,
    out csv.gz          transcript_info_csv           "Transcript info CSV"       "transcripts.csv.gz",
    out parquet         transcript_info_pq            "Transcript info parquet"   "transcripts.parquet",
    out csv.gz          cell_info_csv                 "Cell info CSV"             "cells.csv.gz",
    out parquet         cell_info_pq                  "Cell info parquet"         "cells.parquet",
    out zarr.zip        cell_segmentation             "Cell segmentation result"  "cells.zarr.zip",
    out csv.gz          nucleus_boundaries_csv        "Cell segmentation nucleus polygons CSV"  "nucleus_boundaries.csv.gz",
    out csv.gz          cell_boundaries_csv           "Cell segmentation cell polygons CSV"  "cell_boundaries.csv.gz",
    out parquet         nucleus_boundaries_pq         "Cell segmentation nucleus polygons parquet"  "nucleus_boundaries.parquet",
    out parquet         cell_boundaries_pq            "Cell segmentation cell polygons parquet"  "cell_boundaries.parquet",
    out zarr.zip        analysis_zarr_zip             "Clustering result in zarr.zip format"  "analysis.zarr.zip",
    out zarr.zip        cell_feature_matrix_zarr_zip  "Cell-feature matrix in zarr.zip format"  "cell_feature_matrix.zarr.zip",
    out h5              cell_feature_matrix_h5        "Cell-feature matrix in h5 format"  "cell_feature_matrix.h5",
    out ome.tif         morphology,
    out ome.tif         morphology_mip,
    out ome.tif         morphology_focus,
    out json            experiment_xenium             "Metadata for Xenium Explorer"  "experiment.xenium",
    out html            web_summary                   "Customer-facing web summary"  "analysis_summary.html",
    out path            cell_feature_matrix_mtx       "Cell-feature matrix in MEX format"  "cell_feature_matrix",
    out path            analysis_csv                  "Clustering result in csv format"  "analysis",
    out AuxOutputs      aux_outputs                   "Auxiliary output files",
    out json            gene_panel                    "Gene panel JSON",
)
{
    call XR_PREFLIGHT(
        output_bundle_path = self.output_bundle,
        relabel_params     = self.relabel_params,
        resegment_params   = self.resegment_params,
        import_seg_params  = self.import_seg_params,
    ) using (
        preflight = true,
    )

    call XR_SETUP_INPUTS(
        output_bundle_path = self.output_bundle,
        relabel_params     = self.relabel_params,
        resegment_params   = self.resegment_params,
        import_seg_params  = self.import_seg_params,
    )

    # this runs for all XR subcommands
    # if gene_panel is null it just passes the transcripts forward
    call XR_RELABEL_TRANSCRIPTS(
        mem_model_features  = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        transcripts         = XR_SETUP_INPUTS.xr_min_bundle.transcripts,
        original_gene_panel = XR_SETUP_INPUTS.xr_min_bundle.gene_panel,
        gene_panel          = self.relabel_params.gene_panel,
    )

    # Called by Xenium Ranger "import-segmentation" only
    call XR_IMPORT_SEGMENTATION(
        mem_model_features        = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        cell_segmentation_dataset = XR_SETUP_INPUTS.xr_min_bundle.cell_segmentation,
        morphology                = XR_SETUP_INPUTS.xr_min_bundle.morphology,
        pyramid_manifest          = XR_SETUP_INPUTS.xr_payload.pyramid_manifest,
        imported_nuclei           = XR_SETUP_INPUTS.import_seg_params.nuclei,
        imported_cells            = XR_SETUP_INPUTS.import_seg_params.cells,
        spatial_units             = XR_SETUP_INPUTS.import_seg_params.spatial_units,
        expansion_dist_um         = XR_SETUP_INPUTS.import_seg_params.expansion_dist_um,
        min_cell_area_um2         = XR_SETUP_INPUTS.import_seg_params.min_cell_area_um2,
        max_cell_area_um2         = XR_SETUP_INPUTS.import_seg_params.max_cell_area_um2,
        min_nucleus_area_um2      = XR_SETUP_INPUTS.import_seg_params.min_nucleus_area_um2,
        max_nucleus_area_um2      = XR_SETUP_INPUTS.import_seg_params.max_nucleus_area_um2,
        max_vertices              = XR_SETUP_INPUTS.import_seg_params.max_vertices,
        simplify_epsilon          = XR_SETUP_INPUTS.import_seg_params.simplify_epsilon,
        coordinate_transform      = XR_SETUP_INPUTS.import_seg_params.coordinate_transform,
    ) using (
        disabled = XR_SETUP_INPUTS.disable_import_segmentation,
    )

    # Called by Xenium Ranger "import-segmentation" only
    call XR_IMPORT_TRANSCRIPT_ASSIGNMENTS(
        mem_model_features        = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        cell_segmentation_dataset = XR_SETUP_INPUTS.xr_min_bundle.cell_segmentation,
        transcripts               = XR_SETUP_INPUTS.xr_min_bundle.transcripts,
        transcript_assignment     = XR_SETUP_INPUTS.import_seg_params.transcript_assignment,
        polygons                  = XR_SETUP_INPUTS.import_seg_params.viz_polygons,
        spatial_units             = XR_SETUP_INPUTS.import_seg_params.spatial_units,
        min_area_um2              = XR_SETUP_INPUTS.import_seg_params.min_cell_area_um2,
        max_area_um2              = XR_SETUP_INPUTS.import_seg_params.max_cell_area_um2,
        max_vertices              = XR_SETUP_INPUTS.import_seg_params.max_vertices,
        simplify_epsilon          = XR_SETUP_INPUTS.import_seg_params.simplify_epsilon,
        coordinate_transform      = XR_SETUP_INPUTS.import_seg_params.coordinate_transform,
    ) using (
        disabled = XR_SETUP_INPUTS.disable_import_transcripts,
    )

    # Called by Xenium Ranger "Resegment" only
    call SEGMENT_CELLS(
        seg_partition_cycle_ix = null,
        mem_model_features     = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        morphology             = XR_SETUP_INPUTS.xr_min_bundle.morphology,
        pyramid_manifest       = XR_SETUP_INPUTS.xr_payload.pyramid_manifest,
        segmentation_plan      = XR_SETUP_INPUTS.xr_payload.segmentation_plan,
        segmentation_params    = XR_SETUP_INPUTS.segmentation_params,
    ) using (
        disabled = XR_SETUP_INPUTS.disable_resegment_nuclei,
    )

    call STITCH_SEGMENTATION(
        mem_model_features = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        morphology         = XR_SETUP_INPUTS.xr_min_bundle.morphology,
        pyramid_manifest   = XR_SETUP_INPUTS.xr_payload.pyramid_manifest,
        seg_parts_list     = [SEGMENT_CELLS.seg_parts_list],
    ) using (
        disabled = XR_SETUP_INPUTS.disable_resegment_nuclei,
    )

    call XR_SELECT_DATASET as SELECT_NUCLEI_DATASET(
        original = XR_SETUP_INPUTS.xr_min_bundle.cell_segmentation,
        choices  = {
            "resegment": STITCH_SEGMENTATION.nuclei_segmentation_dataset,
        },
    )

    # Called by Xenium Ranger "Re-Expand" only
    call EXPAND_NUCLEI(
        mem_model_features        = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        morphology                = XR_SETUP_INPUTS.xr_min_bundle.morphology,
        pyramid_manifest          = XR_SETUP_INPUTS.xr_payload.pyramid_manifest,
        nuclei_dataset            = SELECT_NUCLEI_DATASET.dataset,
        max_vertices              = XR_SETUP_INPUTS.segmentation_params.max_vertices,
        simplify_epsilon          = XR_SETUP_INPUTS.segmentation_params.simplify_epsilon,
        expansion_dist_um         = XR_SETUP_INPUTS.segmentation_params.expansion_dist_um,
        is_xr_import_segmentation = false,
    ) using (
        disabled = XR_SETUP_INPUTS.disable_reexpand_nuclei,
    )

    call XR_SELECT_DATASET as SELECT_CELLS_DATASET(
        original = XR_SETUP_INPUTS.xr_min_bundle.cell_segmentation,
        choices  = {
            "import_segmentation": XR_IMPORT_SEGMENTATION.cells,
            "import_transcripts": XR_IMPORT_TRANSCRIPT_ASSIGNMENTS.cells,
            "resegment": EXPAND_NUCLEI.cell_segmentation_dataset,
        },
    )

    call SIMPLE_MERGE_METRICS as MERGE_METRICS(
        summaries = [
            XR_IMPORT_SEGMENTATION.metrics,
            XR_SETUP_INPUTS.xr_payload.summary_cs,
            XR_IMPORT_TRANSCRIPT_ASSIGNMENTS.metrics,
        ],
    )

    call INSITU_COUNTER_CS(
        cells                    = SELECT_CELLS_DATASET.dataset,
        gene_panel               = XR_SETUP_INPUTS.gene_panel,
        transcripts              = XR_RELABEL_TRANSCRIPTS.transcripts,
        morphology               = XR_SETUP_INPUTS.xr_min_bundle.morphology,
        morphology_mip           = XR_SETUP_INPUTS.xr_min_bundle.morphology_mip,
        morphology_focus         = XR_SETUP_INPUTS.xr_min_bundle.morphology_focus,
        calibration_uuid         = XR_SETUP_INPUTS.calibration_uuid,
        mem_model_features       = XR_SETUP_INPUTS.xr_payload.mem_model_features,
        sample_sheet             = XR_SETUP_INPUTS.xr_payload.sample_sheet,
        morphology_fov_json      = XR_SETUP_INPUTS.xr_min_bundle.aux_outputs.morphology_fov_locations,
        overview_scan            = XR_SETUP_INPUTS.xr_min_bundle.aux_outputs.overview_scan,
        overview_scan_fov_json   = XR_SETUP_INPUTS.xr_min_bundle.aux_outputs.overview_scan_fov_locations,
        per_cycle_channel_images = XR_SETUP_INPUTS.xr_min_bundle.aux_outputs.per_cycle_channel_images,
        dx_plot_details          = null,
        resized_overview_image   = XR_SETUP_INPUTS.xr_payload.resized_overview_image,
        input_metrics_summary    = MERGE_METRICS.summary,
        pyramid_manifest         = XR_SETUP_INPUTS.xr_payload.pyramid_manifest,
        segmentation_plan        = XR_SETUP_INPUTS.xr_payload.segmentation_plan,
        telemetry_bundle_files   = [],
        telemetry_bundle_paths   = [],
        pre_computed             = {
            transcript_assignments: XR_IMPORT_TRANSCRIPT_ASSIGNMENTS.transcript_assignments,
        },
        xr_run_data              = {
            command_line:              self.command_line,
            original_software_version: XR_SETUP_INPUTS.original_software_version,
            run_id:                    self.run_id,
            run_timestamp:             self.run_timestamp,
            software_version:          self.software_version,
        },
        xr_table                 = XR_SETUP_INPUTS.xr_payload.xenium_ranger_table,
        spatial_plots            = null,
    )

    return (
        * = INSITU_COUNTER_CS.output_bundle,
    )
}

stage XR_PREFLIGHT(
    in  path            output_bundle_path,
    in  RelabelParams   relabel_params,
    in  ResegmentParams resegment_params,
    in  ImportSegParams import_seg_params,
    src py              "stages/xr_preflight",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

stage XR_SETUP_INPUTS(
    in  path                output_bundle_path,
    in  RelabelParams       relabel_params,
    in  ResegmentParams     resegment_params,
    in  ImportSegParams     import_seg_params,
    out XrMinBundle         xr_min_bundle,
    out XeniumRangerPayload xr_payload,
    out SegmentationParams  segmentation_params,
    out ImportSegParams     import_seg_params,
    out json                gene_panel,
    out bool                disable_resegment_nuclei,
    out bool                disable_reexpand_nuclei,
    out bool                disable_import_segmentation,
    out bool                disable_import_transcripts,
    out string              calibration_uuid,
    out string              original_software_version,
    src py                  "stages/xr_setup_inputs",
) split (
) using (
    mem_gb   = 4,
    vmem_gb  = 16384,
    volatile = strict,
)

#
# @include "_invocation_99_8741c_xr17_reseg_wnuclei.mro"
#

call XENIUM_RANGER_CS(
    output_bundle     = "/dcs04/lieber/marmaypag/spatialHYP_LIBD4195/spatial_HYP/xenium_HYP/raw-data/xenium/20240223__174743__022324_KMon120823/output-XETG00089__0011199__11199X_8741C_HYP__20240223__174831",
    relabel_params    = null,
    resegment_params  = {
        dapi_filter_pe:    null,
        expansion_dist_um: null,
        max_diameter_um:   null,
        max_vertices:      null,
        min_diameter_um:   null,
        resegment_nuclei:  true,
        simplify_epsilon:  null,
    },
    import_seg_params = null,
    run_id            = "99_8741C_xr17_reseg_wnuclei",
    run_timestamp     = "2024-06-12 20:50:18 UTC",
    command_line      = "xeniumranger resegment --xenium-bundle=/dcs04/lieber/marmaypag/spatialHYP_LIBD4195/spatial_HYP/xenium_HYP/raw-data/xenium/20240223__174743__022324_KMon120823/output-XETG00089__0011199__11199X_8741C_HYP__20240223__174831 --resegment-nuclei=true --id=99_8741C_xr17_reseg_wnuclei --localcores=36 --localmem=255 --disable-ui=true --jobmode=local",
    software_version  = "xenium-1.7.1.1",
)
